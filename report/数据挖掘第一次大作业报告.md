## 数据挖掘第一次大作业报告

组长：罗弈桢 2022310868

组员：侯振宇 许若虞

分工：

- 罗弈桢：数据分析、预处理与可视化，消融实验

- 侯振宇：手动实现Logistic Regression算法
- 许若虞：实现PCA-KNN、SVM、FNN、Naive Bayes算法

### 1.问题描述

本次作业要求从Online News Popularity数据集中，根据文章的特征预测该其热度。根据题意将该问题抽象为一个二分类问题，即给定输入特征$x\in \mathbb{R}^{n}$，训练模型$f:\mathbb{R}^{n}\rightarrow\{0,1\}$，对文章是否受欢迎进行预测。

我们实现了五个常见的分类模型，分别为Logistic Regression、PCA-KNN、SVM、FNN和Naive Bayes。关于模型 的实现细节和具体表现分别在第3节和第4节中进行详细介绍。

衡量模型的指标包括Accuracy、AUC和F1 score。三个指标的具体含义将在第3节中介绍。

### 2.数据分析与预处理

#### 2.1 数据分析与可视化

这部分代码在`preprocessing.ipynb`中。

阅读`OnlineNewsPopularity.names`可知该数据集包括了2013至2015年Meshable网站上发布的39797条新闻，统计了61维特征，其中前两维特征分别为新闻的url和发布时间，后58维特征表示了新闻的某些属性，最后1维特征为转发数。可以发现原始数据已经根据发布时间从前到后进行了排序。根据题意，认为shares>=1400为受欢迎，标签为1，否则标签为0。统计得原始数据共包含39644个样本，其中正样本数量为21154，负样本数量为18490。

各个特征的含义、维度和数值类型如下表所示：

<img src="./feat1.png" alt="image-20221218161751937" style="zoom:50%;" /><img src="./feat2.png" alt="image-20221218162032278" style="zoom:50%;" />

对各个数字类型的特征进行归一化并绘制盒图，通过皮尔逊相关系数和卡方检验分析它们与分享次数的关系，有如下几个结论：
- 数据中存在一个离群点，绝大多数样本的`n_unique_tokens`，`n_non_stop_words`和`n_non_stop_unique_tokens`取值都在$[0,1]$之间，因此三个词条应当反映的是比率数值而不是绝对数值，而某一样本的这三个特征取值分别为701,1042,650，需要剔除，否则会影响归一化的结果；

- 部分特征的数值分布比较极端，如`kw_max_min`，该特征的最大值与平均值相差了2个数量级，且观察盒图可以发现绝大多数样本分布在中间，而少数样本分布在较大或较小的区域，这些特征可能会导致后续模型训练中数值不稳定；
  ![image-20221218164735741](./boxplot.png)

- 新闻的关键词的分享次数与极性与分享次数具有更高的相关性。平均关键词与最差关键词的分享次数越多，新闻越偏向正面，则分享次数越多；

    | 特征名                    | 皮尔逊相关系数 |
    | ------------------------- | -------------- |
    | kw_max_min                | 0.0842         |
    | kw_avg_min                | 0.0923         |
    | kw_max_avg                | 0.1197         |
    | kw_avg_avg                | 0.1393         |
    | global_subjectivity       | 0.0681         |
    | global_sentiment_polarity | 0.1193         |
    | rate_negative_words       | -0.0712        |

- 存在一些无用特征，如`n_nonstop_words`，样本的取值分布集中在0和0.99以上，观察该特征值为0的新闻可以发现它只有图片和视频，没有文本，另一方面，该特征与分享次数的皮尔逊相关系数约为0；

进一步地，使用sklearn中实现的PCA和t-SNE方法对特征降至2维并可视化，如下图所示（左为PCA，右为t-SNE，蓝色和橙色的点分别代表正/负样本，由于t-SNE算法运行效率较低，因此只选择了5000个样本做可视化）：

<img src="./dimreduction1.png" alt="image-20221218163919868" style="zoom:50%;" />

可以发现不管采用哪种算法进行降维，正负样本都不是线性可分的，并且正负样本特征的聚类性质不是特别明显，因此使用单个线性分类器或KNN的方法可能无法取得非常理想的结果。

对于weekday和channel两类特征绘制柱状图，如下所示：<img src="./weekday.png" alt="image-20221218162147056" style="zoom:50%;" />

<img src="./channel.png" alt="image-20221218162207031" style="zoom:50%;" />

发现这两类特征在正样本和负样本上的分布具有符合直觉的规律，如周末发布的新闻和与社交媒体、技术等主题相关的新闻更受欢迎，而关于娱乐和世界主题的新闻则不受欢迎。

#### 2.2 数据预处理

数据预处理代码在`preprocessing.py`中，主要包括了以下几个部分：

- 离群点剔除；
- 特征归一化，首先对取值范围比较大的特征取对数，接着使用MinMax进行归一化，即对于第i维特征，$x_{j,i}=\frac{x_{j,i}-\min_k{x_{k,i}}}{\max_k{x_{k,i}}-\min_{k}x_{k,i}}$；
- 数据集分割，实现了两种分割策略，分别为按照时间顺序和随机对数据集进行train:test=4:1的分割；

### 3.模型与实验设置

#### 3.1 实现模型简介

- Logistic Regression

- PCA-KNN

- SVM

- FNN

- Naive Bayes

#### 3.2 评价指标简介

TODO：介绍一下所用的指标

#### 3.3 超参设置

TODO：说明超参的搜索范围和最佳超参

### 4.实验结果与分析

#### 4.1 Benchmark结果

| Model               | Accuracy | AUC  | F1 Score |
| ------------------- | -------- | ---- | -------- |
| Logistic Regression |          |      |          |
| PCA-KNN             |          |      |          |
| SVM                 |          |      |          |
| FNN                 |          |      |          |
| Naive Bayes         |          |      |          |

TODO：调参，报告最佳结果，绘制并分析AUC曲线

####  4.2 消融实验

为了验证第二节中提到的高相关性特征和无用特征，设计了如下实验：

仅考虑训练集，首先将所有特征按照与标签的皮尔逊相关系数从高到低排序，使用前$k$个或后$k$个特征作为输入，比较五个模型的AUC结果。

#### 4.2 场景1分析

TODO：可解释性分析
本场景下，我们选取逻辑回归模型(Logistic Regression)来进行分析。逻辑回归是一个线性模型，一个样本的预测结果来源于多个特征的加权和。其计算公式如下：
$$ y=\sigma(\beta_0 + \beta_1 x_1 +...+\beta_n x_n),
$$
其中$(\beta_1, \beta_2,..., \beta_n)$ 表示n项特征的权重，$\sigma(x)=\frac{1}{1+e^{(-x)}}$为Sigmoid函数。本次实验中输入数据包含58维特征，即n=58。在数据预处理过程中，所有的特征被放缩到[0,1]之间，所以权重可以直接反映该项特征对最终预测的贡献度。从各项特征的权重大小中，我们可以找出受欢迎新闻的特征以及影响新闻受欢迎性的积极和消极因素。以下是部分特征的权重。从中可以观察到，"self_reference_max_shares"、"kw_max_min"是让新闻受欢迎的特征，情感偏极端的新闻和社交媒体相关的内容也比较容易传播。相反地，特别积极正面的情感"avg_positive_polarity"、"global_rate_positive_words"反而不容易传播，并且周二、周三这些工作日发表的文章也比较难成为受欢迎的文章，引用太多其他新闻容易分走读者注意力等等。

```
 self_reference_max_shares	1.3030038017863100
 kw_max_min	1.2280743774325800
 global_sentiment_polarity	0.979687172461446
 avg_negative_polarity	0.8002079479412650
 data_channel_is_socmed	0.7909692905356790
 title_sentiment_polarity	0.7330151654720210
 kw_avg_avg	0.7088845154627420
 weekday_is_saturday	0.5742165612955550
 num_videos	0.5523079709757170
 kw_max_avg	0.5275130109568780
 num_imgs	0.5125231996034780
 kw_min_avg	0.46497099069444200
 n_tokens_title	0.4576180295863530
 ...
 weekday_is_tuesday	-0.6490272016558530
 weekday_is_wednesday	-0.6545017043010620
 data_channel_is_entertainment	-0.6926785231408350
 kw_max_max	-0.8067340188886200
 global_rate_positive_words	-0.9334613180532240
 avg_positive_polarity	-0.9401039126134160
 num_self_hrefs	-2.049860647092770
```

####  4.3 场景2分析

首先对发布时间与特征的关系进行研究，按照各个样本的`time_delta`值分为5类，从每一类中随机选取1000个样本，用PCA和t-SNE方法将特征降维并可视化如下：

![image-20221218205940674](./dimreduction2.png)

可以发现发布时间与特征存在一定关联，如发布时间较早的新闻（`time_delta`在$[582,732]$之间）的PCA降维结果偏向于分布在下半平面，而t-SNE的降维结果则呈现出比较明显的聚类特征。

下表展示了不同时刻训练数据对模型在测试集性能的影响。我们分别选取了距离测试集时间最近的数据和时间最远的数据进行实验，同时也探究了不同训练集大小的影响。从下表可以看出：
- 发布时间最早的新闻与最新发布的新闻作为训练集对模型性能的影响很大。在相同训练数据大小下，使用最新发布的新闻作为训练数据比使用时间较早的数据性能要高出7%～10%。这说明新闻具有相似的实效性，发布时间相近的新闻更倾向于拥有类似的特征。
- 另一方面，我们比较了不同训练集大小对模型性能的影响，即分别选用时间最早的1%、10%数据，和最新发布的1%、10%、50%数据来分析。可以看到，增大训练集的规模可以带来模型性能的提升。将训练从1%提升至10%数据时，使用时间最早（A）部分和最新发布（B）训练得到的模型性能分别有大约2%和5%左右的提升。当继续增大训练集大小时，A部分增加的是发布时间更靠后的数据，B增加的是发布更早的数据，所以使用最新发布50%相对于使用最新发布10%的数据训练模型性能几乎没有提升。所以我们可以得出，当训练数据与测试数据分布较相似时，适度增大训练数据能够在一定范围内提升模型性能。如果增大训练集的数据是无用的数据，则对模型最终性能影响不大。

| 训练数据 | Accuracy | AUC  | F1   |
| ---------- | -------- | ---- | ---- |
| 时间最早 1% | 0.5175 | 0.5219 | 0.5063 |
| 时间最早 10% | 0.5375 | 0.5419 | 0.5200 |
| 时间最早 50% | 0.6134 | 0.6064 | 0.5212 |
| 最新发布 1% | 0.5815 | 0.5851 | 0.6035 |
| 最新发布 10% | 0.6376 | 0.6404 | 0.6512 |
| 最新发布 50% | 0.6411 | 0.6434 | 0.6509 |

我们也对比了在整个训练集中随机采样一定比例的数据用于训练，评估这种情境下训练集大小的影响。结果如下图所示。可以看到，当不考虑时间因素，随机对数据集进行采样时，增大训练集能带来模型性能提升。当增大到一定比例时(<0.5)，继续增大训练集带来的提升并不显著。
<img src="./split_ratio.png" style="zoom:50%;centering:;" />


